{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi modellerar som sagt sannolikheten med klassificering snarare än medlet. Denna metod listar ut beroende sannolikheter, lite lätt sagt vända på sannolikheterna. Det går att göra en regression med denna metod också. Då antar vi att alla händelser är oberoende av varandra och att vårt stickprov är rättvist emot populationen. Om det är sant får vi bra resultat, om det inte är det så får vi ändå någon form av närmvärde och uppfattning. Fungerar på enkla problem. T ex spam/ham. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   class    5572 non-null   object\n",
      " 1   content  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv(\"../data/spam.csv\", encoding=\"latin-1\")\n",
    "# as it is very few rows, we remove those columns\n",
    "df_no_NaN = df.dropna(axis=1)\n",
    "df_no_NaN.columns = [\"class\", \"content\"]\n",
    "df_no_NaN.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df_no_NaN, columns = [\"class\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>class_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  class_spam\n",
       "0     Go until jurong point, crazy.. Available only ...       False\n",
       "1                         Ok lar... Joking wif u oni...       False\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...        True\n",
       "3     U dun say so early hor... U c already then say...       False\n",
       "4     Nah I don't think he goes to usf, he lives aro...       False\n",
       "...                                                 ...         ...\n",
       "5567  This is the 2nd time we have tried 2 contact u...        True\n",
       "5568              Will Ì_ b going to esplanade fr home?       False\n",
       "5569  Pity, * was in mood for that. So...any other s...       False\n",
       "5570  The guy did some bitching but I acted like i'd...       False\n",
       "5571                         Rofl. Its true to its name       False\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "print(repr(X_tfidf))\n",
    "print(X_tfidf[1])\n",
    "print(f\"Min value: {X_tfidf.min()}, max value: {X_tfidf.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För en regression, hur kan vi använda massa text för att förutsäga? Det kan vi inte. Vi måste göra om den till något tal, en vektor. Vi vill ju jämför hur lika de är. Det vanligaste är TF-IDF.  \n",
    "\n",
    "Term frequency så gör vi en tabell för alla ord som förekommer. Vi plockar fram en kvot av hur många som finns och hur de förekommer. Termerna i texten   \n",
    "\n",
    "Inverse document frequency är i stället hur många av alla raderna där termen förekommer.  \n",
    "\n",
    "Om två tal ligger nära varandra så kommer dokumenten vara lika varandra. Det är inget exakt mått utan är en abstrakt likhet. Vi ändrar feature-mängden på något sätt. Vi får en dimension per ord. Vi tar in en vektor med förekomsten av alla ord så står det en etta eller nolla om order förekommer. Det är alltså 8404 tokens (tänk LLM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(\n",
    "    [(\"rf\", RandomForestClassifier()),\n",
    "     (\"svc\", LinearSVC()),\n",
    "     (\"naive_complement\", ComplementNB()),\n",
    "     (\"naive_bernoulli\", BernoulliNB()),\n",
    "     (\"naive_multinomail\", MultinomialNB())], voting=\"hard\")\n",
    "\n",
    "evaluate_model(vote_clf)\n",
    "\n",
    "# we see that a combination of models improves the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utöver voting=hard kan det vara bra att använda n_jobs=-1 för att öka performance (då kommer så många trådar användas som möjligt, alltså parallella beräkningar). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det var just denna metod som användes under väldigt många år som spam-filter av t ex Microsoft. I dag används LLM:er för att det är LLM:er som skriver mejl och är bra på att undvika ord som lätt fastnar i filter osv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online-inlärning är oftast oövervakad inlärning. Vad betyder det? Det finns inget y, ingen responsvariabel, inget facit eller rätt. Saknar labels. KNN fungerar som oövervakad också. Varje exempel vi får in sparar vi och sen så när vi får nya exempel så jämför vi.  \n",
    "\n",
    "En annan metod som heter KMeans Clustering är på ytan lite lik KNN. Men i stället för k nearest neighbours delar vi upp datan i k st klustrar där alla har ett gemensamt medel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisera så att inte skalan påverkar. Då centreras värdena kring 0. Nu behöver vi inte normalisera utan det gör vi framförallt när vi har med sannolikheter att göra pga normalisera innebär att alla värden är mellan 0 och 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans tar slumpmässiga punkter och beräknar medel.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanligare än KMeans i dag så gör vi pre-training i LLM. Vi lär den att läsa (motsvarande klustringsmetod) och lär sig hitta ett sätt att rita ut och sen labla. Det är extremt dyrt att lära den att tokenisera/läsa datan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lunch\n",
    "\n",
    "Tillbaka klockan 13!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans exempel med färger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resten av veckan\n",
    "\n",
    "Vi kommer på onsdag att köra PCA och sen kommer vi in på djupa grejer. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
