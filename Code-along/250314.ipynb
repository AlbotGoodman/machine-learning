{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees\n",
    "## Teori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- en massa if ... then ... else ... satser  \n",
    "- constructing a binary tree over X  \n",
    "- antalet nivåer i trädet kallas depths  \n",
    "- vi försöker minimera entropi (Shannon enthropy)  \n",
    "- entropi ökar med djupet, därför föredrar vi små träd (eller stubbar, djup 2, två noder)  \n",
    "- träden är högst linjära, därför kan vi bryta upp dem i mindre delar  \n",
    "    - då kan många (små) träd rösta för klassificering  \n",
    "- entropi:\n",
    "    - mäter mängden oordning (klassisk definition), mängden möjliga sätt jämfört med mängden utfall  \n",
    "    - maximala mängden sätt som något kan fortgå på  \n",
    "    - det finns mer information när vi har lägre entropi  \n",
    "    - entropi kan vi säga mäter kvalitet genom brus, hög entropi = mycket brus  \n",
    "    - det finns en direkt koppling mellan entropi och gini  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest  \n",
    "\n",
    "- oftast bygger i random forests  \n",
    "- choose random $x \\epsilon \\bold{X}$ and do a split  \n",
    "- right angled decision boundaries  \n",
    "- många träd röstar  \n",
    "- denna metod behöver inte standardiseras eller normaliseras  \n",
    "    - eftersom den bara gör splits\n",
    "- däremot måste den hyperparameteroptimeras (HPO) \n",
    "    - max depth  \n",
    "    - number of trees/estimators  \n",
    "    - några fler beroende på  \n",
    "- vi kan råka ut för kombinatorisk explosion med många hyperparametrar (HP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det går att göra både klassificering och regression med träd. De har däremot väldigt hög bias. Resultaten för trädregression är dock inte så bra och därför ovanligt att de används för regression.  \n",
    "\n",
    "Däremot kan du alltid köra den. Så om du inte skulle ha någon aning om vad du ska köra för modell så går det med träd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eftersom den ser geometrisk ut så kan vi inte göra någon linjär regression.  \n",
    "\n",
    "[någonting] i stället för feature expansion kan vi göra kernel trick och komma undan billigare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ger oss värde mellan 0-1 och visar på hur viktiga våra features är. T ex 0.58 säger att den kunde dra en linje där 58 % av datan är på ena sidan, resten på andra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_tree_reg.predict(X_test)\n",
    "\n",
    "mean_absolute_error(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan inte räkna med att vi får bra stabilitet, vi får höga fel pga stora steg mot regressionsvärdena. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om vi får låg relevans (feature importance = låg) så hamnar alla värden på ena sidan linljen. Så obalanserad data är DT inte bra för. Väldigt känsliga för overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging innebär att vi tar flera slumpmässiga sticprov från samma träningsset och kollar medlet från alla dessa. Ganska likt CV men syftet är för att vi ska få en bättre förutsägelse. I klassifikationsproblem blir det alltså majoritetsröstning. Vi kan alltså ha samma data flera gånger men det spelar ingen roll för att vi vill ha många små träd och det är fortfarande slumpmässigt. Det leder i detta fallet alltså inte till data leakage.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Heart.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I detta fallet är vår target variable AHD, en hjärtsjukdom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [100, 150, 200,\n",
    "                               300], \"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"auto\",\"sqrt\", \"log2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om det tar för lång tid, testa att ta bort \"auto\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), param_grid,\n",
    "                   cv=5, verbose=1, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vill inte ha falska negativa (säga att de är friska när de är sjuka) därför optimerar vi på \"recall\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allmänt problem är att vi kommer få olika resultat när vi kör gång på gång för att de har hög varians. Efter HPO så har vi en bättre chans att få ett bättre resultat men det är inte garanterat. Det är däremot mycket dyrare oftast att också använda sig av HPO men beroende på resultat så vet vi inte om det är värt det eller inte.  \n",
    "\n",
    "Det är pga att det är så mycket slump inblandat. RF ska inte användas i kritiska applikationer, enligt Raphael. Däremot i allmänhet bra att använda som en första modell och för enkla problem kan de vara väldigt kraftfulla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan göra egna voting classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan kombinera olika metoder. Du kan till och med träna dem innan och sen använda dem tillsammans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf = VotingClassifier(\n",
    "    [(\"rf\", RandomForestClassifier()),\n",
    "     (\"svc\", LinearSVC()),\n",
    "     (\"naive_complement\", ComplementNB()),\n",
    "     (\"naive_bernoulli\", BernoulliNB()),\n",
    "     (\"naive_multinomail\", MultinomialNB())], voting=\"hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om du misstänker hög varians så använd \"hard\" voting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generalisation power - stämmer bara när stickproven råkar vara lika\n",
    "\n",
    "data augmentation - boosting - försöker göra något med den mindre datan när det är stor skillnad på storleken av klasserna. Basically boosta den obalanserade klassen. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
