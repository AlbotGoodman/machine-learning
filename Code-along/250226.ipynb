{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teori  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skalering  \n",
    "\n",
    "[först pratade vi om standardisering och normalisering - jag missade när vi ska använda någon av dem]  \n",
    "\n",
    "Om vi reguljariserar så måste vi standardisera, dvs att vi måste ha $\\beta_i$ på samma skala. Även de tillfällen då noll ska betyda \"ingenting\" så behövs ofta skalering.  \n",
    "\n",
    "Y skalerar vi oftast inte eftersom vi vill behålla storleken på responsen (Y) och inte behöva konvertera fram och tillbaka. Men om vi klassificerar och får in sannolikheter så behöver vi skalera eftersom de ska summera till 1 (ett).  \n",
    "\n",
    "Det finns inneboende risk med att skalera. Om datan inte är ~N så [MISSADE NÅGOT HÄR] ser vi inte skillnader.  \n",
    "\n",
    "Oftast beror det på föreskriven metid, alltså vilken regression som används, som säger om vi ska skalera eller inte.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "OLS är ett specialfall av maximum-likelihood metoden (inte korrekt skriven nedqan):  \n",
    "\n",
    "$ max\\bold{CB} \\approx \\prod P \\prod 1-P $  \n",
    "\n",
    "Symbolen $\\prod$ är samma sak som $\\sum$ fast för multiplikation i stället för addition.  \n",
    "\n",
    "Då fungerar inte längre formeln för våra $\\beta$ som vi hade för linjär regression. Det är inte alltid så att vi kan härleda ett b för koefficienterna. I denna kostnadsfunktion finns inget krav på linjaritet. Vi måste alltså hitta ett annat sätt att optimera över konstadsfunktionen. Det finns många sätt men vad vi framför allt för är att vi använder gradient descent - en iterativ metod (vår kostnadsfunktion har nu en annan form).  Den fungerar så bra att vi nästan gett upp alla andra metoder.  \n",
    "\n",
    "Steglängden är viktig. Om ytan är \"knagglig\" så hoppar vi omkring massa (instabilt). Så vad gör vi? Vi kan använda **SGD - stochastic gradient descent**. Då väljer vi bara en slumpmässig punkt i varje iteration i stället för hela stickprovet. Den kan ju då vara var som helst. Nu konvergerar inte metoden längre. Men vi måste däremot ha ett stoppvillkor för att den inte ska fortsätta i all evighet. Vad denna metod gör är att den inte fastnar i lokala minimum. Sen har vi även **mini-batch gradient descent** så väljer vi en slumpmässig delmängd av punkterna och räknar gradienten på. En iterativ metod betyder att vi måste ha stoppvillkor och varje steg vi tar kallas för en epok. Det som är bra att veta är att iterativa metoder kan bli kaotiska.  \n",
    "\n",
    "$ x_{n+1} = r (1 - x_n) $  \n",
    "\n",
    "3.58 är oftast värdet då det blir kaotiskt. Det är en fraktal så de får olika mönster beroende på vilka värden vi välker. Det finns inga analytiska sätt att se om det bryter ut i kaos.  \n",
    "\n",
    "OLS: 0(np²), n - stickprovets storlek, p - antalet dimensioner  \n",
    "SGD: 0(n), därav är SGD är alltid linjär  \n",
    "\n",
    "Vi behöver justera några parametrar för att SGD ska bli bra:  \n",
    "- steglängden bör förändras (adaptive gradient descent)  \n",
    "- moment (tänk att vanlig GD kan fastna i en liten svacka men med momentum kommer den över den och fastnar i den verkliga minimumet) (ADAM - adaptive moment estimation)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
