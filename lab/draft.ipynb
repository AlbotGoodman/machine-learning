{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Machine learning  \n",
    "*Using the cardiovascular disease dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cardio.csv\", sep=\";\")\n",
    "df = df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(data=df, x=\"cardio\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pie(df[\"cholesterol\"].value_counts(), labels=[\"normal\", \"above normal\", \"well above normal\"], autopct=\"%1.1f%%\", startangle=178);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data=df, x=\"age\", hue=\"cardio\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(data=df, x=\"smoke\", hue=\"cardio\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data=df, x=\"weight\", hue=\"gender\", bins=75);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data=df, x=\"height\", hue=\"gender\", bins=60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(data=df, x=\"cardio\", hue=\"gender\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bmi\"] = df[\"weight\"] / (df[\"height\"] / 100) ** 2\n",
    "df[\"bmi\"] = df[\"bmi\"].round(1)\n",
    "df = df[[\"age\", \"gender\", \"height\", \"weight\", \"bmi\", \"ap_hi\", \"ap_lo\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\", \"cardio\"]]\n",
    "df = df[(df[\"bmi\"] > 16) & (df[\"bmi\"] <= 40)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Då labbinstruktionerna hänvisar till Wikipedia används de gränsvärden angivna där. Ursprunglig källa anges vara WHO och hänvisar till att människor med värden under 16 är \"svårt tunna\" medan de med värden över 40 lider av \"fetma klass 3\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_labels = [\"underweight\", \"normal\", \"overweight\", \"obese cl1\", \"obese cl2\", \"obese cl3\"]\n",
    "df[\"bmi_cat\"] = pd.cut(df[\"bmi\"], bins=[16, 18.5, 25, 30, 35, 40, float(\"inf\")], labels=bmi_labels)\n",
    "df = df[[\"age\", \"gender\", \"height\", \"weight\", \"bmi\", \"bmi_cat\", \"ap_hi\", \"ap_lo\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\", \"cardio\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blodtryck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"ap_hi\"] >= 0) & (df[\"ap_hi\"] <= 250) &\n",
    "        (df[\"ap_lo\"] >= 0) & (df[\"ap_lo\"] <= 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2)\n",
    "# sns.boxplot(data=df, y=\"ap_hi\", ax=ax[0])\n",
    "# sns.boxplot(data=df, y=\"ap_lo\", ax=ax[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eftersom många outliers fortfarande är närvarande i datan används nedan IQR-metoden för att rensa fler outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_outliers(df):    \n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    df = df[(df >= lower) & (df <= upper)]\n",
    "    return df\n",
    "\n",
    "df[\"ap_hi\"] = clear_outliers(df[\"ap_hi\"])\n",
    "df[\"ap_lo\"] = clear_outliers(df[\"ap_lo\"])\n",
    "df = df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2)\n",
    "# sns.boxplot(data=df, y=\"ap_hi\", ax=ax[0])\n",
    "# sns.boxplot(data=df, y=\"ap_lo\", ax=ax[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_conditions = [\n",
    "    (df[\"ap_hi\"] <= 90) | (df[\"ap_lo\"] <= 60), # with outlier I need | instead of & otherwise I get unknown values\n",
    "    ((df[\"ap_hi\"] >= 90) & (df[\"ap_hi\"] < 120)) & (df[\"ap_lo\"] < 80),\n",
    "    ((df[\"ap_hi\"] >= 120) & (df[\"ap_hi\"] < 130)) & (df[\"ap_lo\"] < 80),\n",
    "    ((df[\"ap_hi\"] >= 130) & (df[\"ap_hi\"] < 140)) | ((df[\"ap_lo\"] >= 80) & (df[\"ap_lo\"] < 90)),\n",
    "    ((df[\"ap_hi\"] >= 140) & (df[\"ap_hi\"] < 180)) | ((df[\"ap_lo\"] >= 90) & (df[\"ap_lo\"] < 120)),\n",
    "    (df[\"ap_hi\"] >= 180) | (df[\"ap_lo\"] >= 120)\n",
    "]\n",
    "bp_labels = [\n",
    "    \"hypotension\", \n",
    "    \"normal\", \n",
    "    \"elevated\", \n",
    "    \"hypertension st1\", \n",
    "    \"hypertension st2\", \n",
    "    \"hypertension crisis\"\n",
    "]\n",
    "\n",
    "df[\"ap_cat\"] = np.select(bp_conditions, bp_labels, default=\"unknown\")\n",
    "df = df[[\"age\", \"gender\", \"height\", \"weight\", \"bmi\", \"bmi_cat\", \"ap_hi\", \"ap_lo\", \"ap_cat\", \"cholesterol\", \"gluc\", \"smoke\", \"alco\", \"active\", \"cardio\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Då labbinstruktionerna hänvisar till Healthline används de gränsvärden angivna där. Det framgår även en källhänvisning till brittiska NHS som anger gränsvärden även för lågt blodtryck vilket implementerats här likaså. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiseringar\n",
    "### Andel sjukdomar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_gluc_labels = [\"normal\", \"above normal\", \"well above normal\"]\n",
    "binary_labels = [\"no\", \"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: barplots instead? \n",
    "\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "# sns.countplot(data=df, x=\"bmi_cat\", order=bmi_labels, hue=\"cardio\", ax=ax[0, 0])\n",
    "# ax[0, 0].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[0, 0].set_title(\"Body Mass Index\\n\", fontweight=\"bold\")\n",
    "# ax[0, 0].set_xlabel(\"\")\n",
    "# ax[0, 0].set_ylabel(\"\")\n",
    "\n",
    "# sns.countplot(data=df, x=\"ap_cat\", order=bp_labels, hue=\"cardio\", ax=ax[0, 1])\n",
    "# ax[0, 1].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[0, 1].set_title(\"Blood Pressure\\n\", fontweight=\"bold\")\n",
    "# ax[0, 1].set_xlabel(\"\")\n",
    "# ax[0, 1].set_ylabel(\"\")\n",
    "\n",
    "# sns.countplot(data=df, x=(df[\"age\"] // 365.25).astype(int), hue=\"cardio\", ax=ax[1, 0])\n",
    "# ax[1, 0].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[1, 0].set_title(\"Age\\n\", fontweight=\"bold\")\n",
    "# ax[1, 0].set_xlabel(\"\")\n",
    "# ax[1, 0].set_ylabel(\"\")\n",
    "\n",
    "# sns.countplot(data=df, x=\"cholesterol\", hue=\"cardio\", ax=ax[1, 1])\n",
    "# ax[1, 1].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[1, 1].set_xticks([0, 1, 2])\n",
    "# ax[1, 1].set_xticklabels(chol_gluc_labels)\n",
    "# ax[1, 1].set_title(\"Cholesterol Levels\\n\", fontweight=\"bold\")\n",
    "# ax[1, 1].set_xlabel(\"\")\n",
    "# ax[1, 1].set_ylabel(\"\")\n",
    "\n",
    "# sns.countplot(data=df, x=\"gluc\", hue=\"cardio\", ax=ax[2, 0])\n",
    "# ax[2, 0].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[2, 0].set_xticks([0, 1, 2])\n",
    "# ax[2, 0].set_xticklabels(chol_gluc_labels)\n",
    "# ax[2, 0].set_title(\"Glucose Levels\\n\", fontweight=\"bold\")\n",
    "# ax[2, 0].set_xlabel(\"\")\n",
    "# ax[2, 0].set_ylabel(\"\")\n",
    "\n",
    "# sns.countplot(data=df, x=\"active\", hue=\"cardio\", ax=ax[2, 1])\n",
    "# ax[2, 1].tick_params(axis=\"x\", rotation=45)\n",
    "# ax[2, 1].set_xticks([0, 1])\n",
    "# ax[2, 1].set_xticklabels(binary_labels)\n",
    "# ax[2, 1].set_title(\"Physically Active\\n\", fontweight=\"bold\")\n",
    "# ax[2, 1].set_xlabel(\"\")\n",
    "# ax[2, 1].set_ylabel(\"\")\n",
    "\n",
    "# # fig.delaxes(ax[2, 1])  # Remove the empty subplot\n",
    "\n",
    "# fig.suptitle(\"\\nVisualisation of CVD risk factors\", fontweight=\"bold\", fontsize=20)\n",
    "# plt.subplots_adjust(hspace=0.4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: change all values to numeric\n",
    "# numerical_columns = df.describe().columns.to_list()\n",
    "# corr = df[numerical_columns].corr()\n",
    "# plt.figure(figsize=(9, 7))\n",
    "# sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, square=True, linewidths=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI och vikt samt systoliskt och diastoliskt blodtryck kan ignoreras pga deras uppenbara relationer. Detsamma skulle kunna sägas för glukos och kolesterol.  \n",
    "\n",
    "Mer intressanta observationer för detta dataset är att rökning har en viss relation till alkoholkonsumption men även kön.  \n",
    "\n",
    "För syftet med labben är den sista raden den enda viktiga, korrelationer med vår responsvariabel. Då BMI har en högre korrelation än de separata variablerna för höjd och vikt vore det intressant att veta hur vår nuvarande kategoriska variabel för blodtryck påverkas. Andra kolumner av värde är ålder och kolesterol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df.copy().drop(columns=[\"height\", \"weight\", \"bmi\", \"ap_hi\", \"ap_lo\"])\n",
    "df_b = df.copy().drop(columns=[\"height\", \"weight\", \"bmi_cat\", \"ap_cat\"])\n",
    "\n",
    "df_a = pd.get_dummies(df_a, columns=[\"gender\", \"bmi_cat\", \"ap_cat\"])\n",
    "df_b = pd.get_dummies(df_b, columns=[\"gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! Cutting down dataset size !!\n",
    "*For  more performance during experimentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a.shape is (62830, 20)\n",
    "# cutting it down to increase performance\n",
    "\n",
    "def dataset_trimmer(df, remainder=0.125):\n",
    "    \n",
    "    df_cut = df.copy()\n",
    "    df_cut = df_cut.sample(frac=remainder, random_state=42)\n",
    "\n",
    "    return df_cut\n",
    "\n",
    "\n",
    "df_a = dataset_trimmer(df_a)\n",
    "df_b = dataset_trimmer(df_b)\n",
    "\n",
    "# TODO: denna är just nu random så jag kan inte jämföra resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(df):\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        df.drop(\"cardio\", axis=1), \n",
    "        df[\"cardio\"], \n",
    "        test_size=0.3, \n",
    "        random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, \n",
    "        y_temp, \n",
    "        test_size=0.5, \n",
    "        random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train_a, X_val_a, X_test_a, y_train_a, y_val_a, y_test_a = splits(df_a)\n",
    "X_train_b, X_val_b, X_test_b, y_train_b, y_val_b, y_test_b = splits(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardiser(X_train, X_val, X_test):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_val_std = scaler.transform(X_val)\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_val_std, X_test_std\n",
    "\n",
    "\n",
    "def normaliser(X_train, X_val, X_test):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_norm = scaler.fit_transform(X_train)\n",
    "    X_val_norm = scaler.transform(X_val)\n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_norm, X_val_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_val_a, X_test_a = standardiser(X_train_a, X_val_a, X_test_a)\n",
    "X_train_b, X_val_b, X_test_b = standardiser(X_train_b, X_val_b, X_test_b)\n",
    "X_train_a, X_val_a, X_test_a = normaliser(X_train_a, X_val_a, X_test_a)\n",
    "X_train_b, X_val_b, X_test_b = normaliser(X_train_b, X_val_b, X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"log_reg\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"params\": {\n",
    "            \"C\": [10, 1, 0.1, 0.01],\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "            \"solver\": [\"saga\", \"liblinear\", \"lbfgs\"],\n",
    "            \"max_iter\": [100, 1000, 10000]\n",
    "        }\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"gamma\": [\"scale\", \"auto\", 0.1, 0.01],\n",
    "            \"kernel\": [\"linear\", \"poly\", \"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"sgd\": {\n",
    "        \"model\": SGDClassifier(),\n",
    "        \"params\": {\n",
    "            \"loss\": [\"log_loss\", \"hinge\", \"modified_huber\"],\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "            \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "            \"max_iter\": [1000, 1500, 2000]\n",
    "        }\n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [2, 5, 10],\n",
    "            \"weights\": [\"uniform\", \"distance\"], \n",
    "            \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "            \"p\": [1, 2] # 1: Manhattan, 2: euklidiskt avstånd\n",
    "        }\n",
    "    },\n",
    "    \"rforest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [5, 50, 500], \n",
    "            \"max_depth\": [None, 2, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"bootstrap\": [True, False]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model_info in param_grids.items():\n",
    "    print(f\"\\nTraining {model_name} ...\")\n",
    "\n",
    "    model = model_info[\"model\"]\n",
    "    params = model_info[\"params\"]\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        cv=5,\n",
    "        scoring=\"recall\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_a, y_train_a)\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"best_score\": grid_search.best_score_,\n",
    "        \"val_score\": grid_search.score(X_val_a, y_val_a)\n",
    "    }\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Validation score: {grid_search.score(X_train_a, y_train_a):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v1\n",
    "\n",
    "Training log_reg ...\n",
    "Best parameters: {'C': 10, 'max_iter': 100, 'penalty': None, 'solver': 'lbfgs'}\n",
    "Validation score: 0.6098\n",
    "\n",
    "Training svm ...\n",
    "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Validation score: 0.6181\n",
    "\n",
    "Training sgd ...\n",
    "Best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': 'l2'}\n",
    "Validation score: 0.6705\n",
    "\n",
    "Training knn ...\n",
    "Best parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
    "Validation score: 0.7376\n",
    "\n",
    "Training rforest ...\n",
    "Best parameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "Validation score: 0.7785\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v2\n",
    "\n",
    "Training log_reg ...\n",
    "Best parameters: {'C': 10, 'max_iter': 100, 'penalty': None, 'solver': 'lbfgs'}\n",
    "Validation score: 0.6098\n",
    "\n",
    "Training svm ...\n",
    "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Validation score: 0.6181\n",
    "\n",
    "Training sgd ...\n",
    "Best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 2000, 'penalty': 'l2'}\n",
    "Validation score: 0.6117\n",
    "\n",
    "Training knn ...\n",
    "Best parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
    "Validation score: 0.7376\n",
    "\n",
    "Training rforest ...\n",
    "Best parameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
    "Validation score: 0.8508\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "v3\n",
    "\n",
    "Training log_reg ...\n",
    "Best parameters: {'C': 10, 'max_iter': 100, 'penalty': None, 'solver': 'lbfgs'}\n",
    "Validation score: 0.6098\n",
    "\n",
    "Training svm ...\n",
    "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Validation score: 0.6181\n",
    "\n",
    "Training sgd ...\n",
    "Best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1500, 'penalty': 'l2'}\n",
    "Validation score: 0.6904\n",
    "\n",
    "Training knn ...\n",
    "Best parameters: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
    "Validation score: 0.7376\n",
    "\n",
    "Training rforest ...\n",
    "Best parameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
    "Validation score: 0.8246\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>{'alpha': 0.0001, 'loss': 'modified_huber', 'm...</td>\n",
       "      <td>0.751817</td>\n",
       "      <td>0.657851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rforest</th>\n",
       "      <td>{'bootstrap': True, 'max_depth': None, 'min_sa...</td>\n",
       "      <td>0.645784</td>\n",
       "      <td>0.631405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.625176</td>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>{'C': 10, 'max_iter': 100, 'penalty': None, 's...</td>\n",
       "      <td>0.60868</td>\n",
       "      <td>0.568595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.575332</td>\n",
       "      <td>0.54876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               best_params best_score  \\\n",
       "sgd      {'alpha': 0.0001, 'loss': 'modified_huber', 'm...   0.751817   \n",
       "rforest  {'bootstrap': True, 'max_depth': None, 'min_sa...   0.645784   \n",
       "knn      {'algorithm': 'ball_tree', 'n_neighbors': 5, '...   0.625176   \n",
       "log_reg  {'C': 10, 'max_iter': 100, 'penalty': None, 's...    0.60868   \n",
       "svm           {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   0.575332   \n",
       "\n",
       "        val_score  \n",
       "sgd      0.657851  \n",
       "rforest  0.631405  \n",
       "knn      0.619835  \n",
       "log_reg  0.568595  \n",
       "svm       0.54876  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(results).T\n",
    "scores.sort_values(by=\"val_score\", ascending=False, inplace=True)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
