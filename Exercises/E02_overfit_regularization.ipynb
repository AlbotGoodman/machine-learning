{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/kokchun/Machine-learning-AI22/blob/main/Exercises/E03_overfit_regularization.ipynb\" target=\"_parent\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; to see hints and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Overfit and regularization exercises \n",
    "\n",
    "---\n",
    "These are introductory exercises in Machine learning with focus in **overfitting and regularization** .\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that sometimes you don't get exactly the same answer as I get, but it doesn't neccessarily mean it is wrong. Could be some parameters, randomization, that we have different. Also very important is that in the future there won't be any answer sheets, use your skills in data analysis, mathematics and statistics to back up your work.</p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that in cases when you start to repeat code, try not to. Create functions to reuse code instead. </p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Remember</b> to use <b>descriptive variable, function, index </b> and <b> column names</b> in order to get readable code </p>\n",
    "\n",
    "The number of stars (\\*), (\\*\\*), (\\*\\*\\*) denotes the difficulty level of the task\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Tips data EDA (*)\n",
    "\n",
    "In the whole exercise, we will work with the \"tips\" dataset from seaborn dataset. Start by loading dataset \"tips\" from the ```load_dataset``` method in seaborn module. The goal will be to use polynomial linear regression to predict tips. \n",
    "\n",
    "&nbsp; a) Start by doing some initial EDA such as info(), describe().\n",
    "\n",
    "&nbsp; b) Use describe only on those columns that are relevant to get statistical information from. Plot the descriptive statistics for each numerical column, with a adequate plot type (e.g. barplot).\n",
    "\n",
    "&nbsp; c) Based on the initial EDA, make some more plots on things you think could be worthwhile to investigate. \n",
    "\n",
    "&nbsp; d) Try discuss your findings with yourself/colleague and draw some conclusions if possible. Note that in reality, it is important to be able to communicate your findings so that other people in your team/customers/stakeholders etc. get an understanding of the data and realizes the importance of your role as a data scientist/analyst.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "\n",
    "b)\n",
    "<img src=\"../assets/df_describe.png\" height=\"300\"/>\n",
    "\n",
    "c) Here are some example plots\n",
    "\n",
    "<img src=\"../assets/tips_EDA.png\" height=\"300\"/>\n",
    "\n",
    "<img src=\"../assets/tips_smoke_sex.png\" width=\"500\"/>\n",
    "\n",
    "<img src=\"../assets/tips_bar_sex.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "d) For example: \n",
    "- there are almost double amount of females represented in the dataset\n",
    "- there are very few tables with 1 person eating, and they usually give very low tip\n",
    "- female and male tip somewhat similar\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_np_scalars_without_type():\n",
    "    from IPython import get_ipython\n",
    "    formatter = get_ipython().display_formatter.formatters['text/plain']\n",
    "    formatter.for_type(np.float64, lambda num, p, cycle: p.text(str(float(num))))\n",
    "\n",
    "\n",
    "show_np_scalars_without_type()\n",
    "\n",
    "df = sns.load_dataset(\"tips\")\n",
    "\n",
    "print(\"Head:\"), display(df.head())\n",
    "print(df[\"day\"].unique()), print()\n",
    "print(\"Info:\"), display(df.info())\n",
    "print(\"Describe:\"), display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, corner=True, height=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe_T = df.describe().transpose().reset_index()\n",
    "df_describe_T.drop(columns=[\"count\"], inplace=True)\n",
    "df_describe_T_melt = df_describe_T.melt(id_vars=\"index\")\n",
    "\n",
    "sns.barplot(data=df_describe_T_melt, x=\"value\", y=\"variable\", hue=\"index\")\n",
    "plt.title(\"tip_dataset.describe() visualised\\n\", fontweight=\"bold\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"x\")\n",
    "plt.gca().set_facecolor('whitesmoke')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numeric = df.describe().columns.to_list()\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 8))\n",
    "\n",
    "for ax, col in zip(axes, cols_numeric):\n",
    "    sns.boxplot(data=df, y=col, ax=ax)\n",
    "    ax.set_title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"sex\", row=\"smoker\")\n",
    "g.map(sns.scatterplot, \"total_bill\", \"tip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numeric = df.describe().columns.to_list()\n",
    "cols_categoric = df.drop(columns=cols_numeric)\n",
    "\n",
    "for col in cols_categoric:\n",
    "    display(df[col].value_counts().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train|test split (*)\n",
    "\n",
    "Split the data into training part and testing part, using sklearn's train_test_split with test size of 0.3 and random_state 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_numeric = df[cols_numeric]\n",
    "X = df_numeric.drop(columns=[\"tip\"])\n",
    "X = np.array(X)\n",
    "y = df[\"tip\"]\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Feature standardization (*)\n",
    "\n",
    "We need to normalize the data and in this case will be using feature standardization. Implement this yourself following this formula:\n",
    "\n",
    "$$X_{train}' = \\frac{X_{train}-\\mu_{train}}{\\sigma_{train}}$$\n",
    "\n",
    "$$X_{test}' = \\frac{X_{test}-\\mu_{train}}{\\sigma_{train}}$$\n",
    "\n",
    ", where $'$ denotes scaled, $\\mu_{train}$ is the mean of the training data, $\\sigma_{train}$ is the standard deviation of the training data. Note that it is very important that the mean and standard deviation is computed from the training data and not from testing data to avoid data leakage. Control the standard deviation and mean of $X_{train}'$ and $X_{test}'$. Is the results as you expect, why, why not?\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "scaled_X_train (total_bill, size) mean: [ 6.79195262e-17 -1.98534000e-16]\n",
    "\n",
    "scaled_X_test (total_bill, size) mean: [-0.19137999 -0.04477934]\n",
    "\n",
    "scaled_X_train (total_bill, size) std: [1. 1.]\n",
    "\n",
    "scaled_X_test (total_bill, size) std: [0.92495673 1.06638889]\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardise:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._train_mean = None\n",
    "        self._train_std = None\n",
    "\n",
    "\n",
    "    def norm(self, X, split):\n",
    "        \"\"\"Normalise features using training statistics.\"\"\"\n",
    "        X_norm = X.copy()\n",
    "\n",
    "        if split == \"train\":\n",
    "            self._train_mean = np.mean(X_norm, axis=0)\n",
    "            self._train_std = np.std(X_norm, axis=0, ddof=1)\n",
    "        elif split == \"test\":\n",
    "            if self._train_mean is None:\n",
    "                raise ValueError(\"Normalise the training data first\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {split}\")\n",
    "\n",
    "        X_norm = (X_norm - self._train_mean) / self._train_std\n",
    "            \n",
    "        return X_norm\n",
    "\n",
    "\n",
    "scaler = Standardise()\n",
    "X_train_scaled, X_test_scaled = scaler.norm(X_train, \"train\"), scaler.norm(X_test, \"test\")\n",
    "X_train_scaled[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Polynomial features (*)\n",
    "\n",
    "We want to investigate ```Polynomialfeatures``` from scikit-klearn in this task. Start by instantiating an object of type ```PolynomialFeatures``` with degree 2. Now do the following: \n",
    "\n",
    "- use the method fit on $X_{train}'$\n",
    "- transform $X_{train}'$\n",
    "- transform $X_{test}'$\n",
    "\n",
    "Compare this transformed $X_{test}'$ with $X_{test}''$ where $X_{test}''$ comes from fitting the polynomial features to $X_{test}'$ and transforming $X_{test}'$. You can check directly by using ```==``` and then sum it up. If the value is same as the length, then you know that they are the same, as a boolean True evaluates to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly_prime = poly.fit_transform(X_train)\n",
    "poly_prime = poly.transform(X_test)\n",
    "poly_double_prime = poly.fit_transform(X_test)\n",
    "\n",
    "poly_prime.all() == poly_double_prime.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Polynomial regression  (*)\n",
    "\n",
    "We will now investigate the training loss and testing loss for different degrees of polynomial. Loop through degrees 1 to 4 (inclusive) and:\n",
    "- instantiate an object of PolynomialFeatures with that degree\n",
    "- fit and transform $X_{train}'$ and $X_{test}$ to create polynomial features\n",
    "- perform linear regression on these polynomial features (polynomial regression)\n",
    "- predict on both the training and testing data to record RMSE for training and testing for each iteration of the loop\n",
    "\n",
    "Now plot the results in the same figure. Do you notice anything special? \n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "<img src=\"../assets/E3_overfitting.png\" height=\"300\"/>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "rmse = [] # [train, test]\n",
    "\n",
    "for d in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_train_d = poly.fit_transform(X_train_scaled)\n",
    "    X_test_d = poly.transform(X_test_scaled)\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train_d, y_train)\n",
    "    y_hat_train = linear_model.predict(X_train_d)\n",
    "    y_hat_test = linear_model.predict(X_test_d)\n",
    "    rmse_train = root_mean_squared_error(y_true=y_train, y_pred=y_hat_train)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_hat_test)\n",
    "    rmse.append([rmse_train, rmse_test])\n",
    "\n",
    "arr = np.array(rmse)\n",
    "x = np.arange(1,5)\n",
    "sns.lineplot(x=x, y=arr[:, 0]) # train\n",
    "sns.lineplot(x=x, y=arr[:, 1]) # test\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Regularization methods (*)\n",
    "\n",
    "Now we will try the regularization methods: ridge regression, lasso regression and elasticnet regression. In the following tasks, use degree = 4. \n",
    "\n",
    "&nbsp; a) Use ridge regression with cross-validation and test out different alpha-values. I used $\\alpha=[0.01, 0.1, 0.5, 1, 5, 10]$ in the cross-validation. \n",
    "- Check which alpha, that the cross-validation chose as the best one. \n",
    "- Check the weights.\n",
    "- Check MAE, MSE, RMSE.\n",
    "\n",
    "&nbsp; b) Use lasso regression with cross-validation and choose number of alphas to 100. If you get a warning that the algorithm is not converging, increase the max iterations, I chose 10000 iterations. \n",
    "- Check which alpha, that the cross-validation chose as the best one. \n",
    "- Check the weights.\n",
    "- Check MAE, MSE, RMSE.\n",
    "\n",
    "&nbsp; c) Use elasticnet regression with cross-validation and choose number of alphas to 100. If you get a warning that the algorithm is not converging, increase the max iterations, I chose 10000 iterations. Choose a set of $\\ell_1$ ratios for it to try out. I chose $\\ell_1 = [.001, .01, .05, .1, .5, .9, .95, 1]$\n",
    "- Check which alpha, that the cross-validation chose as the best one. \n",
    "- Check the weights.\n",
    "- Check MAE, MSE, RMSE.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a) \n",
    "\n",
    "Chosen alpha from cross-validation 5.0\n",
    "\n",
    "Weights: [ 0.          0.91469637  0.23893931 -0.67583593  0.20550801 -0.01369317\n",
    " -0.26007685  0.31867863 -0.03429744 -0.12484035  0.16000319 -0.18105113\n",
    "  0.24878399 -0.12692847  0.05002613]\n",
    "\n",
    "Mean absolute error: 0.831\n",
    "\n",
    "Mean squared error: 2.208\n",
    "\n",
    "Root mean squared error: 1.486\n",
    "\n",
    "b) \n",
    "\n",
    "Chosen alpha from cross-validation 0.208\n",
    "\n",
    "Weights: [ 0.          0.23469707  0.         -0.         -0.          0.\n",
    "  0.08814685  0.09735986  0.          0.03219702  0.          0.\n",
    "  0.         -0.          0.        ]\n",
    "\n",
    "Mean absolute error: 0.823\n",
    "\n",
    "Mean squared error: 1.345\n",
    "\n",
    "Root mean squared error: 1.160\n",
    "\n",
    "c)\n",
    "\n",
    "Chosen alpha from cross-validation 0.107\n",
    "\n",
    "Mean absolute error: 0.761\n",
    "\n",
    "Root mean squared error: 1.139\n",
    "\n",
    "L1_ratio: 0.9\n",
    "\n",
    "Weights: [ 0.          0.23469707  0.         -0.         -0.          0.\n",
    "  0.08814685  0.09735986  0.          0.03219702  0.          0.\n",
    "  0.         -0.          0.        ]\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDGE\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "a = [0.01, 0.1, 0.5, 1, 5, 10]\n",
    "\n",
    "model = RidgeCV(alphas = a)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# calculating metrics\n",
    "temp_train = [mean_absolute_error(y_train, y_pred_train), mean_squared_error(y_train, y_pred_train), root_mean_squared_error(y_train, y_pred_train)]\n",
    "temp_test = [mean_absolute_error(y_test, y_pred_test), mean_squared_error(y_test, y_pred_test), root_mean_squared_error(y_test, y_pred_test)]\n",
    "ridgeCV_scores = []\n",
    "ridgeCV_scores.append(temp_train)\n",
    "ridgeCV_scores.append(temp_test)\n",
    "temp = pd.DataFrame(ridgeCV_scores)\n",
    "temp.columns = [\"MAE\", \"MSE\", \"RMSE\"]\n",
    "temp.rename(index={0: \"train\", 1: \"test\"}, inplace=True)\n",
    "\n",
    "print(f\"Chosen alpha: {model.alpha_}\")\n",
    "print(f\"Weights: {model.coef_}\")\n",
    "print(\"Error metrics:\")\n",
    "display(temp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred): # helper\n",
    "    \n",
    "    return [\n",
    "        r2_score(y_true, y_pred),\n",
    "        mean_absolute_error(y_true, y_pred),\n",
    "        mean_squared_error(y_true, y_pred),\n",
    "        root_mean_squared_error(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "\n",
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    train_metrics = calculate_metrics(y_train, y_pred_train)\n",
    "    test_metrics = calculate_metrics(y_test, y_pred_test)\n",
    "\n",
    "    df_metrics = pd.DataFrame([train_metrics, test_metrics])\n",
    "    df_metrics.columns = [\"R2\", \"MAE\", \"MSE\", \"RMSE\"]\n",
    "    df_metrics.rename(index={0: \"train\", 1: \"test\"}, inplace=True)\n",
    "    \n",
    "    print(f\"Chosen alpha: {model.alpha_}\")\n",
    "    print(f\"Weights: {model.coef_}\")\n",
    "    print(\"Error metrics:\")\n",
    "    display(df_metrics.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDGE\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge_model = RidgeCV(alphas = [0.01, 0.1, 0.5, 1, 5, 10])\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_train = ridge_model.predict(X_train_scaled)\n",
    "y_pred_test = ridge_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO \n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_model = LassoCV(eps = 0.001, n_alphas = 100, max_iter=10000, cv=5)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "y_pred_train = lasso_model.predict(X_train_scaled)\n",
    "y_pred_test = lasso_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELASTIC NET\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "elasticnet_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps = 0.001, n_alphas = 100, max_iter=10000)\n",
    "elasticnet_model.fit(X_train_scaled, y_train)\n",
    "y_pred_train = elasticnet_model.predict(X_train_scaled)\n",
    "y_pred_test = elasticnet_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON\n",
    "\n",
    "print(\"RIDGE\\n\")\n",
    "evaluate(ridge_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"LASSO\\n\")\n",
    "evaluate(lasso_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"ELASTIC NET\\n\")\n",
    "evaluate(elasticnet_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Kokchun Giang\n",
    "\n",
    "[LinkedIn][linkedIn_kokchun]\n",
    "\n",
    "[GitHub portfolio][github_portfolio]\n",
    "\n",
    "[linkedIn_kokchun]: https://www.linkedin.com/in/kokchungiang/\n",
    "[github_portfolio]: https://github.com/kokchun/Portfolio-Kokchun-Giang\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
