{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/kokchun/Machine-learning-AI22/blob/main/Exercises/E02_sklearn.ipynb\" target=\"_parent\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; to see hints and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scikit-learn exercises \n",
    "\n",
    "---\n",
    "These are introductory exercises in Machine learning with focus in **scikit-learn** .\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that sometimes you don't get exactly the same answer as I get, but it doesn't neccessarily mean it is wrong. Could be some parameters, randomization, that we have different. Also very important is that in the future there won't be any answer sheets, use your skills in data analysis, mathematics and statistics to back up your work.</p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that in cases when you start to repeat code, try not to. Create functions to reuse code instead. </p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Remember</b> to use <b>descriptive variable, function, index </b> and <b> column names</b> in order to get readable code </p>\n",
    "\n",
    "The number of stars (\\*), (\\*\\*), (\\*\\*\\*) denotes the difficulty level of the task\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. EDA (*)\n",
    "\n",
    "In the whole exercise, we will work with the \"mpg\" dataset from seaborn dataset. Start by loading dataset \"mpg\" from the ```load_dataset``` method in seaborn module. The goal will be to use linear regression to predict mpg - miles per gallon. \n",
    "\n",
    "&nbsp; a) Start by doing some initial EDA such as info(), describe() and figure out what you want to do with the missing values.\n",
    "\n",
    "&nbsp; b) Use describe only on those columns that are relevant to get statistical information from. \n",
    "\n",
    "&nbsp; c) Make some plots on some of the columns that you find interesting.\n",
    "\n",
    "&nbsp; d) Check if there are any columns you might want to drop. \n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a) I have chosen to drop the rows, but it doesn't neccessary have to be the best method. Maybe some NaNs should be filled somehow?\n",
    "\n",
    "b)\n",
    "|      |      mpg |   cylinders |   displacement |   horsepower |   weight |   acceleration |\n",
    "|:-----|---------:|------------:|---------------:|-------------:|---------:|---------------:|\n",
    "| mean | 23.4459  |     5.47194 |        194.412 |     104.469  | 2977.58  |       15.5413  |\n",
    "| std  |  7.80501 |     1.70578 |        104.644 |      38.4912 |  849.403 |        2.75886 |\n",
    "| min  |  9       |     3       |         68     |      46      | 1613     |        8       |\n",
    "| 25%  | 17       |     4       |        105     |      75      | 2225.25  |       13.775   |\n",
    "| 50%  | 22.75    |     4       |        151     |      93.5    | 2803.5   |       15.5     |\n",
    "| 75%  | 29       |     8       |        275.75  |     126      | 3614.75  |       17.025   |\n",
    "| max  | 46.6     |     8       |        455     |     230      | 5140     |       24.8     |\n",
    "\n",
    "\n",
    "c) Here are some example plots\n",
    "\n",
    "<img src=\"../assets/EDA_mpg.png\" height=\"400\"/>\n",
    "\n",
    "d) I have chosen to drop the columns origin and name. Think yourself if it is reasonable and feel free to experiment. Also there might be some domain experts in our class, that you can ask. \n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"mpg\")\n",
    "df[\"horsepower\"].unique()\n",
    "df.dropna(inplace=True)\n",
    "df.drop(columns=[\"origin\", \"name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, corner=True, height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train|test split (*)\n",
    "\n",
    "We want to predict the \"mpg\", split up X and y, and perform train|test split using scikit-learn. Choose test_size of 0.2 and random_state 42. Control the shapes of each X_train, X_test, y_train, y_test.  \n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "Do a manual calculation to check against the shapes after train|test split. \n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"mpg\"])\n",
    "# X.insert(0, \"Intercept\", 1)\n",
    "y = df[\"mpg\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function for evaluation (*)\n",
    "\n",
    "Create a function for training a regression model, predicting and computing the metrics MAE, MSE, RMSE. It should take in parameters of X_train, X_test, y_train, y_test, model. Now create a linear regression model using scikit-learns ```LinearRegression()``` (OLS normal equation with SVD) and call your function to get metrics. \n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "MAE 2.50\n",
    "\n",
    "MSE 10.50\n",
    "\n",
    "RMSE 3.24\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, y_hat):\n",
    "\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "    R2 = r2_score(y, y_hat)\n",
    "    MAE = mean_absolute_error(y, y_hat)\n",
    "    MSE = mean_squared_error(y, y_hat)\n",
    "    RMSE = root_mean_squared_error(y, y_hat)\n",
    "\n",
    "    return {\n",
    "        \"R2\": R2,\n",
    "        \"MAE\": MAE,\n",
    "        \"MSE\": MSE,\n",
    "        \"RMSE\": RMSE,\n",
    "    }\n",
    "\n",
    "\n",
    "def lr(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    train_eval = evaluate(y_train, y_hat_train)\n",
    "    test_eval = evaluate(y_test, y_hat_test)\n",
    "\n",
    "    return (train_eval, test_eval)\n",
    "\n",
    "\n",
    "linear = lr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Compare models (*)\n",
    "\n",
    "Create the following models \n",
    "- Linear regression (SVD)\n",
    "- Linear regression (SVD) with scaled data (feature standardization)\n",
    "- Polynomial linear regression with degree 1\n",
    "- Polynomial linear regression with degree 2\n",
    "- Polynomial linear regression with degree 3\n",
    "\n",
    "Make a DataFrame with evaluation metrics and model. Which model performed overall best?\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "|      |   Linear regr. SVD |   Linear regr. SVD scaled |   Linear regr. SGD |   Polynom. regr. deg 1 |   Polynom. regr. deg 2 |   Polynom. regr. deg 3 |\n",
    "|:-----|-------------------:|--------------------------:|-------------------:|-----------------------:|-----------------------:|-----------------------:|\n",
    "| mae  |            2.50386 |                   2.50386 |            2.53515 |                2.50386 |                1.98048 |                2.11788 |\n",
    "| mse  |           10.5024  |                  10.5024  |           10.8908  |               10.5024  |                7.41986 |                9.27353 |\n",
    "| rmse |            3.24074 |                   3.24074 |            3.30012 |                3.24074 |                2.72394 |                3.04525 |\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(X_train, X_test):\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_std = scaler.transform(X_train)\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "\n",
    "def lr_std(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    X_train, X_test = standardise(X_train, X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    train_eval = evaluate(y_train, y_hat_train)\n",
    "    test_eval = evaluate(y_test, y_hat_test)\n",
    "\n",
    "    return (train_eval, test_eval)\n",
    "\n",
    "\n",
    "def plr(X_train, y_train, X_test, y_test, degree=1, std=False):\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    if std == True:\n",
    "        X_train, X_test = standardise(X_train, X_test)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "    X_test = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    train_eval = evaluate(y_train, y_hat_train)\n",
    "    test_eval = evaluate(y_test, y_hat_test)\n",
    "\n",
    "    return (train_eval, test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = lr(X_train, y_train, X_test, y_test)\n",
    "linear_std = lr_std(X_train, y_train, X_test, y_test)\n",
    "poly1 = plr(X_train, y_train, X_test, y_test)\n",
    "poly2 = plr(X_train, y_train, X_test, y_test, 2)\n",
    "poly3 = plr(X_train, y_train, X_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = [key for key in linear[0].keys()]\n",
    "rows = [\"linear\", \"linear_std\", \"poly1\", \"poly2\", \"poly3\"]\n",
    "results_train = pd.DataFrame(columns=rows, index=cols)\n",
    "results_test = pd.DataFrame(columns=rows, index=cols)\n",
    "for model_name, model_results in zip(rows, [linear, linear_std, poly1, poly2, poly3]):\n",
    "    results_train[model_name] = pd.Series(model_results[0])\n",
    "    results_test[model_name] = pd.Series(model_results[1])\n",
    "\n",
    "print(\"Training results:\")\n",
    "display(results_train)\n",
    "print(\"Testing results:\")\n",
    "display(results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Further explorations (**)\n",
    "\n",
    "Feel free to further explore the dataset, for example you could choose to \n",
    "- drop different columns\n",
    "- find out feature importance in polynomial models\n",
    "- fine tune further for a specific model by exploring hyperparameters (check documentation which type of parameters that can be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plr(X_train, y_train, X_test, y_test, degree=1, std=False):\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    if std == True:\n",
    "        X_train, X_test = standardise(X_train, X_test)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "    X_test = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    train_eval = evaluate(y_train, y_hat_train)\n",
    "    test_eval = evaluate(y_test, y_hat_test)\n",
    "\n",
    "    return (train_eval, test_eval), y_hat_test\n",
    "\n",
    "\n",
    "poly1, y_hat_degree_1 = plr(X_train, y_train, X_test, y_test, degree=1, std=False)\n",
    "error_list = []\n",
    "\n",
    "for d in range(1, 11):\n",
    "    _, y_hat_d = plr(X_train, y_train, X_test, y_test, degree=d, std=False)\n",
    "    error_list += [root_mean_squared_error(y_test, y_hat_d)]\n",
    "\n",
    "fig, ax = plt.figure(), plt.axes()\n",
    "\n",
    "ax.plot(range(1, len(error_list)+1), error_list, \".-\")\n",
    "ax.set(title=\"Elbow\", xlabel=\"Degree\", ylabel=\"Root Mean Squared Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_hat_degree_1)\n",
    "sns.regplot(x=y_test, y=y_hat_degree_1, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "\n",
    "def plr(X_train, y_train, X_test, y_test, degree=1, std=False, reg=False):\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    if std == True:\n",
    "        X_train, X_test = standardise(X_train, X_test)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "    X_test = poly.transform(X_test)\n",
    "\n",
    "    if reg == True:\n",
    "        ratios = [0.1, 0.5, 0.7, 0.9, 1.0]\n",
    "        model = ElasticNetCV(\n",
    "            l1_ratio=ratios, \n",
    "            eps = 0.001, \n",
    "            n_alphas = 100, \n",
    "            max_iter=10000)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f\"L1 ratio: {model.l1_ratio_}\")\n",
    "        print(f\"alpha {model.alpha_}\")\n",
    "\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    train_eval = evaluate(y_train, y_hat_train)\n",
    "    test_eval = evaluate(y_test, y_hat_test)\n",
    "\n",
    "    return (train_eval, test_eval)\n",
    "\n",
    "\n",
    "metrics = plr(X_train, y_train, X_test, y_test, degree=1, std=True, reg=True)\n",
    "\n",
    "cols = [key for key in metrics[0].keys()]\n",
    "rows = [\"poly_elastic\"]\n",
    "results_train = pd.DataFrame(columns=rows, index=cols)\n",
    "results_test = pd.DataFrame(columns=rows, index=cols)\n",
    "for model_name, model_results in zip(rows, [metrics]):\n",
    "    results_train[model_name] = pd.Series(model_results[0])\n",
    "    results_test[model_name] = pd.Series(model_results[1])\n",
    "\n",
    "print(\"Training results:\")\n",
    "display(results_train)\n",
    "print(\"Testing results:\")\n",
    "display(results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Kokchun Giang\n",
    "\n",
    "[LinkedIn][linkedIn_kokchun]\n",
    "\n",
    "[GitHub portfolio][github_portfolio]\n",
    "\n",
    "[linkedIn_kokchun]: https://www.linkedin.com/in/kokchungiang/\n",
    "[github_portfolio]: https://github.com/kokchun/Portfolio-Kokchun-Giang\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
